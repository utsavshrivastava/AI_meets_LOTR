{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ilShCTZhehL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgLcfmP7hehQ",
    "outputId": "c7b81e85-542e-4630-b02c-4203be7c1733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17019368130090459604\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4815519744\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7549479406538207553\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0ZPVXuFKhehR"
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 60\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 20\n",
    "LSTM_DIM = 256\n",
    "LAYER_COUNT = 4\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOmDHZYYhehR",
    "outputId": "8c21c558-82a4-4b3d-e260-e996b9a6b794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2588993 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/complete_lotr.txt\", \"rb\") as f:\n",
    "    text = f.read().decode(encoding='utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jya3D_i1hehR",
    "outputId": "88795d74-4f30-4d15-e1f8-a7225569aaa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Rings for the Elven-kings under the sky,\r\n",
      "               Seven for the Dwarf-lords in their halls of stone,\r\n",
      "            Nine for Mortal Men doomed to die,\r\n",
      "              One for the Dark Lord on his dark throne\r\n",
      "           In the Land of Mordo\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYUpWggxhehS",
    "outputId": "6b0faf74-7504-4583-a5d3-128b35c6cbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 unique characters\n",
      "dict_items([('\\t', 0), ('\\n', 1), ('\\r', 2), (' ', 3), ('!', 4), ('\"', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), (',', 10), ('-', 11), ('.', 12), ('/', 13), ('0', 14), ('1', 15), ('2', 16), ('3', 17), ('4', 18), ('5', 19), ('6', 20), ('7', 21), ('8', 22), ('9', 23), (':', 24), (';', 25), ('=', 26), ('?', 27), ('A', 28), ('B', 29), ('C', 30), ('D', 31), ('E', 32), ('F', 33), ('G', 34), ('H', 35), ('I', 36), ('J', 37), ('K', 38), ('L', 39), ('M', 40), ('N', 41), ('O', 42), ('P', 43), ('Q', 44), ('R', 45), ('S', 46), ('T', 47), ('U', 48), ('V', 49), ('W', 50), ('X', 51), ('Y', 52), ('Z', 53), ('_', 54), ('`', 55), ('a', 56), ('b', 57), ('c', 58), ('d', 59), ('e', 60), ('f', 61), ('g', 62), ('h', 63), ('i', 64), ('j', 65), ('k', 66), ('l', 67), ('m', 68), ('n', 69), ('o', 70), ('p', 71), ('q', 72), ('r', 73), ('s', 74), ('t', 75), ('u', 76), ('v', 77), ('w', 78), ('x', 79), ('y', 80), ('z', 81), ('É', 82), ('Ó', 83), ('á', 84), ('â', 85), ('ä', 86), ('é', 87), ('ê', 88), ('ë', 89), ('í', 90), ('î', 91), ('ó', 92), ('ô', 93), ('ú', 94), ('û', 95), ('–', 96)])\n"
     ]
    }
   ],
   "source": [
    "#Generating Vocabulary, character to index  and index to character dictionary\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "char_to_idx = {c:i for i,c in enumerate(vocab)}\n",
    "idx_to_char = {i:c for c,i in char_to_idx.items()}\n",
    "\n",
    "print('{} unique characters'.format(len(vocab)))\n",
    "print(char_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bZXUAy2QhehS"
   },
   "outputs": [],
   "source": [
    "def batch_generator(text, batch_size = BATCH_SIZE, sequence_size = SEQUENCE_LEN, vocab_size = vocab_size):\n",
    "    n_steps = (len(text)-sequence_size) // (batch_size)\n",
    "    while True:\n",
    "        for batch_idx in range(n_steps):\n",
    "            x = np.zeros((batch_size,sequence_size,vocab_size))\n",
    "            y = np.zeros((batch_size, vocab_size))\n",
    "\n",
    "            batch_start = batch_idx*batch_size\n",
    "\n",
    "            for sents_idx in range(batch_size):\n",
    "              sent_start = batch_start + sents_idx\n",
    "\n",
    "              for s in range(sequence_size):\n",
    "                x[sents_idx, s, char_to_idx[text[sent_start + s]]] = 1\n",
    "              y[sents_idx,char_to_idx[text[sent_start + s + 1]]] = 1\n",
    "            \n",
    "            yield x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EPbUcGeahehS"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for i in range(LAYER_COUNT):\n",
    "        model.add(\n",
    "            tf.keras.layers.LSTM(LSTM_DIM,\n",
    "                                 return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
    "                                 input_shape = (SEQUENCE_LEN, vocab_size)\n",
    "                                )\n",
    "            )\n",
    "        model.add(tf.keras.layers.Dropout(DROPOUT))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size,\n",
    "                                    activation='softmax'\n",
    "                                   ))\n",
    "    adam = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLRfzQ_QhehT",
    "outputId": "5b427b33-681a-471e-d136-a6fe1032ea3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 256)           362496    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 97)                24929     \n",
      "=================================================================\n",
      "Total params: 1,963,361\n",
      "Trainable params: 1,963,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                             min_delta=0, patience=3,\n",
    "                                             verbose=0,\n",
    "                                             mode='auto')\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                monitor='loss', verbose=1, save_best_only=True, \n",
    "                                                mode='min')\n",
    "desired_callbacks = [earlystop, checkpoint]\n",
    "training_model = build_model()    \n",
    "print(training_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mmbwir0ChehT",
    "outputId": "1aecf164-c7ed-4a2f-8aa1-f82415c4eec9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\anaconda3\\envs\\NLP-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5056/5056 [==============================] - 794s 156ms/step - loss: 2.4532 - accuracy: 0.3277\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.02093, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/20\n",
      "5056/5056 [==============================] - 800s 158ms/step - loss: 1.5703 - accuracy: 0.5362\n",
      "\n",
      "Epoch 00002: loss improved from 2.02093 to 1.50747, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/20\n",
      "5056/5056 [==============================] - 796s 157ms/step - loss: 1.4352 - accuracy: 0.5718\n",
      "\n",
      "Epoch 00003: loss improved from 1.50747 to 1.39778, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/20\n",
      "5056/5056 [==============================] - 796s 157ms/step - loss: 1.3699 - accuracy: 0.5886\n",
      "\n",
      "Epoch 00004: loss improved from 1.39778 to 1.33982, saving model to model_weights_saved.hdf5\n",
      "Epoch 5/20\n",
      "5056/5056 [==============================] - 796s 157ms/step - loss: 1.3276 - accuracy: 0.5990\n",
      "\n",
      "Epoch 00005: loss improved from 1.33982 to 1.30158, saving model to model_weights_saved.hdf5\n",
      "Epoch 6/20\n",
      "5056/5056 [==============================] - 799s 158ms/step - loss: 1.2982 - accuracy: 0.6071\n",
      "\n",
      "Epoch 00006: loss improved from 1.30158 to 1.27460, saving model to model_weights_saved.hdf5\n",
      "Epoch 7/20\n",
      "5056/5056 [==============================] - 805s 159ms/step - loss: 1.2769 - accuracy: 0.6126\n",
      "\n",
      "Epoch 00007: loss improved from 1.27460 to 1.25533, saving model to model_weights_saved.hdf5\n",
      "Epoch 8/20\n",
      "5056/5056 [==============================] - 806s 159ms/step - loss: 1.2593 - accuracy: 0.6170\n",
      "\n",
      "Epoch 00008: loss improved from 1.25533 to 1.23891, saving model to model_weights_saved.hdf5\n",
      "Epoch 9/20\n",
      "5056/5056 [==============================] - 806s 159ms/step - loss: 1.2456 - accuracy: 0.6205\n",
      "\n",
      "Epoch 00009: loss improved from 1.23891 to 1.22579, saving model to model_weights_saved.hdf5\n",
      "Epoch 10/20\n",
      "5056/5056 [==============================] - 805s 159ms/step - loss: 1.2338 - accuracy: 0.6237\n",
      "\n",
      "Epoch 00010: loss improved from 1.22579 to 1.21464, saving model to model_weights_saved.hdf5\n",
      "Epoch 11/20\n",
      "5056/5056 [==============================] - 806s 159ms/step - loss: 1.2228 - accuracy: 0.6265\n",
      "\n",
      "Epoch 00011: loss improved from 1.21464 to 1.20496, saving model to model_weights_saved.hdf5\n",
      "Epoch 12/20\n",
      "5056/5056 [==============================] - 803s 159ms/step - loss: 1.2145 - accuracy: 0.6290\n",
      "\n",
      "Epoch 00012: loss improved from 1.20496 to 1.19748, saving model to model_weights_saved.hdf5\n",
      "Epoch 13/20\n",
      "5056/5056 [==============================] - 799s 158ms/step - loss: 1.2069 - accuracy: 0.6305\n",
      "\n",
      "Epoch 00013: loss improved from 1.19748 to 1.18986, saving model to model_weights_saved.hdf5\n",
      "Epoch 14/20\n",
      "5056/5056 [==============================] - 794s 157ms/step - loss: 1.1994 - accuracy: 0.6324\n",
      "\n",
      "Epoch 00014: loss improved from 1.18986 to 1.18300, saving model to model_weights_saved.hdf5\n",
      "Epoch 15/20\n",
      "5056/5056 [==============================] - 793s 157ms/step - loss: 1.1938 - accuracy: 0.6342\n",
      "\n",
      "Epoch 00015: loss improved from 1.18300 to 1.17748, saving model to model_weights_saved.hdf5\n",
      "Epoch 16/20\n",
      "5056/5056 [==============================] - 791s 156ms/step - loss: 1.1888 - accuracy: 0.6355\n",
      "\n",
      "Epoch 00016: loss improved from 1.17748 to 1.17246, saving model to model_weights_saved.hdf5\n",
      "Epoch 17/20\n",
      "5056/5056 [==============================] - 791s 156ms/step - loss: 1.1832 - accuracy: 0.6369\n",
      "\n",
      "Epoch 00017: loss improved from 1.17246 to 1.16691, saving model to model_weights_saved.hdf5\n",
      "Epoch 18/20\n",
      "5056/5056 [==============================] - 790s 156ms/step - loss: 1.1780 - accuracy: 0.6379\n",
      "\n",
      "Epoch 00018: loss improved from 1.16691 to 1.16245, saving model to model_weights_saved.hdf5\n",
      "Epoch 19/20\n",
      "5056/5056 [==============================] - 791s 156ms/step - loss: 1.1744 - accuracy: 0.6389\n",
      "\n",
      "Epoch 00019: loss improved from 1.16245 to 1.15890, saving model to model_weights_saved.hdf5\n",
      "Epoch 20/20\n",
      "5056/5056 [==============================] - 790s 156ms/step - loss: 1.1697 - accuracy: 0.6404\n",
      "\n",
      "Epoch 00020: loss improved from 1.15890 to 1.15479, saving model to model_weights_saved.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = training_model.fit_generator(\n",
    "    batch_generator(text),\n",
    "    steps_per_epoch = (len(text)-SEQUENCE_LEN) // (BATCH_SIZE),\n",
    "    #max_queue_size=1, # no more than one queued batch in RAM\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=desired_callbacks,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xtf94VE2SQug"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-191ea02b442e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPUN_UXPSTQb"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

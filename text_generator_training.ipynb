{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ilShCTZhehL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import string\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgLcfmP7hehQ",
    "outputId": "c7b81e85-542e-4630-b02c-4203be7c1733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16584205962796674014\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4815519744\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16393774557564032374\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0ZPVXuFKhehR"
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 60\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 20\n",
    "LSTM_DIM = 256\n",
    "LAYER_COUNT = 4\n",
    "DROPOUT = 0.2\n",
    "TEXT_CLEANING_RE = \"[\\t\\n\\r_`]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOmDHZYYhehR",
    "outputId": "8c21c558-82a4-4b3d-e260-e996b9a6b794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2529564 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/complete_lotr_precleaned.txt\", \"rb\") as f:\n",
    "    text = f.read().decode(encoding='utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jya3D_i1hehR",
    "outputId": "88795d74-4f30-4d15-e1f8-a7225569aaa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "This tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses of the yet more ancient history that preceded it. It was begun soon after _The Hobbit_ was written and before its publication in 1937; \n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYUpWggxhehS",
    "outputId": "6b0faf74-7504-4583-a5d3-128b35c6cbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 unique characters\n",
      "dict_items([(' ', 0), ('!', 1), ('\"', 2), (\"'\", 3), ('(', 4), (')', 5), ('*', 6), (',', 7), ('-', 8), ('.', 9), ('/', 10), ('0', 11), ('1', 12), ('2', 13), ('3', 14), ('4', 15), ('5', 16), ('6', 17), ('7', 18), ('8', 19), ('9', 20), (':', 21), (';', 22), ('=', 23), ('?', 24), ('a', 25), ('b', 26), ('c', 27), ('d', 28), ('e', 29), ('f', 30), ('g', 31), ('h', 32), ('i', 33), ('j', 34), ('k', 35), ('l', 36), ('m', 37), ('n', 38), ('o', 39), ('p', 40), ('q', 41), ('r', 42), ('s', 43), ('t', 44), ('u', 45), ('v', 46), ('w', 47), ('x', 48), ('y', 49), ('z', 50), ('á', 51), ('â', 52), ('ä', 53), ('é', 54), ('ê', 55), ('ë', 56), ('í', 57), ('î', 58), ('ó', 59), ('ú', 60), ('û', 61), ('–', 62)])\n"
     ]
    }
   ],
   "source": [
    "#Generating Vocabulary, character to index  and index to character dictionary\n",
    "text = re.sub(\" +\",\" \",text.lower())\n",
    "text = re.sub(TEXT_CLEANING_RE,\"\", text)\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "char_to_idx = {c:i for i,c in enumerate(vocab)}\n",
    "idx_to_char = {i:c for c,i in char_to_idx.items()}\n",
    "\n",
    "print('{} unique characters'.format(len(vocab)))\n",
    "print(char_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bZXUAy2QhehS"
   },
   "outputs": [],
   "source": [
    "def batch_generator(text, batch_size = BATCH_SIZE, sequence_size = SEQUENCE_LEN, vocab_size = vocab_size):\n",
    "    n_steps = (len(text)-sequence_size) // (batch_size)\n",
    "    while True:\n",
    "        for batch_idx in range(n_steps):\n",
    "            x = np.zeros((batch_size,sequence_size,vocab_size))\n",
    "            y = np.zeros((batch_size, vocab_size))\n",
    "\n",
    "            batch_start = batch_idx*batch_size\n",
    "\n",
    "            for sents_idx in range(batch_size):\n",
    "              sent_start = batch_start + sents_idx\n",
    "\n",
    "              for s in range(sequence_size):\n",
    "                x[sents_idx, s, char_to_idx[text[sent_start + s]]] = 1\n",
    "              y[sents_idx,char_to_idx[text[sent_start + s + 1]]] = 1\n",
    "            \n",
    "            yield x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EPbUcGeahehS"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for i in range(LAYER_COUNT):\n",
    "        model.add(\n",
    "            tf.keras.layers.LSTM(LSTM_DIM,\n",
    "                                 return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
    "                                 input_shape = (SEQUENCE_LEN, vocab_size)\n",
    "                                )\n",
    "            )\n",
    "        model.add(tf.keras.layers.Dropout(DROPOUT))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size,\n",
    "                                    activation='softmax'\n",
    "                                   ))\n",
    "    adam = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLRfzQ_QhehT",
    "outputId": "5b427b33-681a-471e-d136-a6fe1032ea3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 256)           327680    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 63)                16191     \n",
      "=================================================================\n",
      "Total params: 1,919,807\n",
      "Trainable params: 1,919,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                             min_delta=0, patience=3,\n",
    "                                             verbose=0,\n",
    "                                             mode='auto')\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                monitor='loss', verbose=1, save_best_only=True, \n",
    "                                                mode='min')\n",
    "desired_callbacks = [earlystop, checkpoint]\n",
    "training_model = build_model()    \n",
    "print(training_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mmbwir0ChehT",
    "outputId": "1aecf164-c7ed-4a2f-8aa1-f82415c4eec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\anaconda3\\envs\\NLP-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4835/4835 [==============================] - 692s 142ms/step - loss: 2.3587 - accuracy: 0.3251\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.97432, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/20\n",
      "4835/4835 [==============================] - 712s 147ms/step - loss: 2.1740 - accuracy: 0.3682\n",
      "\n",
      "Epoch 00002: loss did not improve from 1.97432\n",
      "Epoch 3/20\n",
      "4835/4835 [==============================] - 715s 148ms/step - loss: 1.6906 - accuracy: 0.4916\n",
      "\n",
      "Epoch 00003: loss improved from 1.97432 to 1.63427, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/20\n",
      "4835/4835 [==============================] - 719s 149ms/step - loss: 1.6487 - accuracy: 0.5025\n",
      "\n",
      "Epoch 00004: loss improved from 1.63427 to 1.60440, saving model to model_weights_saved.hdf5\n",
      "Epoch 5/20\n",
      "4835/4835 [==============================] - 719s 149ms/step - loss: 1.4860 - accuracy: 0.5459\n",
      "\n",
      "Epoch 00005: loss improved from 1.60440 to 1.44142, saving model to model_weights_saved.hdf5\n",
      "Epoch 6/20\n",
      "4835/4835 [==============================] - 720s 149ms/step - loss: 1.3928 - accuracy: 0.5707\n",
      "\n",
      "Epoch 00006: loss improved from 1.44142 to 1.36263, saving model to model_weights_saved.hdf5\n",
      "Epoch 7/20\n",
      "4835/4835 [==============================] - 722s 149ms/step - loss: 1.3400 - accuracy: 0.5851\n",
      "\n",
      "Epoch 00007: loss improved from 1.36263 to 1.31632, saving model to model_weights_saved.hdf5\n",
      "Epoch 8/20\n",
      "4835/4835 [==============================] - 722s 149ms/step - loss: 1.3056 - accuracy: 0.5947\n",
      "\n",
      "Epoch 00008: loss improved from 1.31632 to 1.28547, saving model to model_weights_saved.hdf5\n",
      "Epoch 9/20\n",
      "4835/4835 [==============================] - 724s 150ms/step - loss: 1.2819 - accuracy: 0.6012\n",
      "\n",
      "Epoch 00009: loss improved from 1.28547 to 1.26359, saving model to model_weights_saved.hdf5\n",
      "Epoch 10/20\n",
      "4835/4835 [==============================] - 725s 150ms/step - loss: 1.3852 - accuracy: 0.5758\n",
      "\n",
      "Epoch 00010: loss did not improve from 1.26359\n",
      "Epoch 11/20\n",
      "4835/4835 [==============================] - 726s 150ms/step - loss: 1.4260 - accuracy: 0.5631\n",
      "\n",
      "Epoch 00011: loss did not improve from 1.26359\n",
      "Epoch 12/20\n",
      "4835/4835 [==============================] - 728s 150ms/step - loss: 1.3741 - accuracy: 0.5771\n",
      "\n",
      "Epoch 00012: loss did not improve from 1.26359\n"
     ]
    }
   ],
   "source": [
    "history = training_model.fit_generator(\n",
    "    batch_generator(text),\n",
    "    steps_per_epoch = (len(text)-SEQUENCE_LEN) // (BATCH_SIZE),\n",
    "    #max_queue_size=1, # no more than one queued batch in RAM\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=desired_callbacks,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xtf94VE2SQug"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-191ea02b442e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPUN_UXPSTQb"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
